year,title,authors,publication,link,category,demo,data,software,bibtex,abstract,poster,posterTitle,posterAuthors,posterConference,posterYear,posterLocation,pageCategory,download,downloadName,downloadDescription,downloadLink,downloadDate,downloadLinkNames,new,notes
2023,Navigating Data Scarcity: Pretraining for Medical Utterance Classification,"DoJune Min, Verónica Pérez-Rosas, Rada Mihalcea",Proceedings of the 5th Clinical Natural Language Processing Workshop 2023,https://aclanthology.org/2023.clinicalnlp-1.8.pdf,"NLP for Healthcare, Conversational Technologies",,,,"@inproceedings{min-etal-2023-navigating,     title = ""Navigating Data Scarcity: Pretraining for Medical Utterance Classification"",     author = ""Min, Do June  and       Perez-Rosas, Veronica  and       Mihalcea, Rada"",     booktitle = ""Proceedings of the 5th Clinical Natural Language Processing Workshop"",     month = jul,     year = ""2023"",     address = ""Toronto, Canada"",     publisher = ""Association for Computational Linguistics"",     url = ""https://aclanthology.org/2023.clinicalnlp-1.8"",     doi = ""10.18653/v1/2023.clinicalnlp-1.8"",     pages = ""59--68"", }","  Pretrained language models leverage self-supervised learning to use large amounts of unlabeled text for learning contextual representations of sequences. However, in the domain of medical conversations, the availability of large, public datasets is limited due to issues of privacy and data management. In this paper, we study the effectiveness of dialog-aware pretraining objectives and multiphase training in using unlabeled data to improve LMs training for medical utterance classification. The objectives of pretraining for dialog awareness involve tasks that take into account the structure of conversations, including features such as turn-taking and the roles of speakers. The multiphase training process uses unannotated data in a sequence that prioritizes similarities and connections between different domains. We empirically evaluate these methods on conversational dialog classification tasks in the medical and counseling domains, and find that multiphase training can help achieve higher performance than standard pretraining or finetuning.",,,,,,,LIT,FALSE,,,,,,TRUE,
2023,Emergent Linear Representations in World Models of Self-Supervised Sequence Models,"Neel Nanda, Andrew Lee, Martin Wattenberg",,https://arxiv.org/pdf/2309.00941.pdf,"Conversational Technologies, Language Modelling",,,,"@article{nanda2023emergent,   title={Emergent Linear Representations in World Models of Self-Supervised Sequence Models},   author={Nanda, Neel and Lee, Andrew and Wattenberg, Martin},   journal={arXiv preprint arXiv:2309.00941},   year={2023} }","How do sequence models represent their decision-making process? Prior work suggests that Othello-playing neural network learned nonlinear models of the board state (Li et al., 2023). In this work, we provide evidence of a closely related linear representation of the board. In particular, we show that probing for ""my colour"" vs. ""opponent's colour"" may be a simple yet powerful way to interpret the model's internal state. This precise understanding of the internal representations allows us to control the model's behaviour with simple vector arithmetic. Linear representations enable significant interpretability progress, which we demonstrate with further exploration of how the world model is computed.",,,,,,,LIT,FALSE,,,,,,TRUE,
2023,Scalable Performance Analysis for Vision-Language Models,"Santiago Castro*, Oana Ignat*, Rada Mihalcea (* = equal contribution)",*SEM 2023,https://aclanthology.org/2023.starsem-1.26.pdf,Vision and Text,,,,"@inproceedings{castro-etal-2023-scalable,</br>
    title = ""Scalable Performance Analysis for Vision-Language Models"",</br>
    author = ""Castro, Santiago  and</br>
      Ignat, Oana  and</br>
      Mihalcea, Rada"",</br>
    booktitle = ""Proceedings of the The 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)"",</br>
    month = jul,</br>
    year = ""2023"",</br>
    address = ""Toronto, Canada"",</br>
    publisher = ""Association for Computational Linguistics"",</br>
    url = ""https://aclanthology.org/2023.starsem-1.26"",</br>
    pages = ""284--294"",</br>
    abstract = ""Joint vision-language models have shown great performance over a diverse set of tasks. However, little is known about their limitations, as the high dimensional space learned by these models makes it difficult to identify semantic errors. Recent work has addressed this problem by designing highly controlled probing task benchmarks. Our paper introduces a more scalable solution that relies on already annotated benchmarks. Our method consists of extracting a large set of diverse features from a vision-language benchmark and measuring their correlation with the output of the target model. We confirm previous findings that CLIP behaves like a bag of words model and performs better with nouns and verbs; we also uncover novel insights such as CLIP getting confused by concrete words. Our framework is available at https://github.com/MichiganNLP/Scalable-VLM-Probing and can be used with other multimodal models and benchmarks."",</br>
}","Joint vision-language models have shown great performance over a diverse set of tasks. However, little is known about their limitations, as the high dimensional space learned by these models makes it difficult to identify semantic errors. Recent work has addressed this problem by designing highly controlled probing task benchmarks. Our paper introduces a more scalable solution that relies on already annotated benchmarks. Our method consists of extracting a large set of diverse features from a vision-language benchmark and measuring their correlation with the output of the target model. We confirm previous findings that CLIP behaves like a bag of words model and performs better with nouns and verbs; we also uncover novel insights such as CLIP getting confused by concrete words. Our framework is available at https://github.com/MichiganNLP/Scalable-VLM-Probing and can be used with other multimodal models and benchmarks.",probing_clip_poster_2023,Scalable Performance Analysis for Vision-Language Models,"Santiago Castro*, Oana Ignat*, Rada Mihalcea (* = equal contribution)",*SEM,2023,"Toronto, Canada",LIT,TRUE,Scalable Vision-Language Model Probing (code),Framework to probe Vision-Language Models on language properties,https://github.com/MichiganNLP/Scalable-VLM-Probing,19-Jun-23,Code,TRUE,
2023,Empathy Identification Systems are not Accurately Accounting for Context,"Andrew Lee, Jonathan Kummerfeld, Larry An, Rada Mihalcea",EACL 2023,https://aclanthology.org/2023.eacl-main.123/,"NLP for Healthcare, Conversational Technologies",,,,"@inproceedings{lee2023empathy,   title={Empathy Identification Systems are not Accurately Accounting for Context},   author={Lee, Andrew and Kummerfeld, Jonathan and An, Larry and Mihalcea, Rada},   booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},   pages={1678--1687},   year={2023} }","Understanding empathy in text dialogue data is a difficult, yet critical, skill for effective human-machine interaction. In this work, we ask whether systems are making meaningful progress on this challenge. We consider a simple model that checks if an input utterance is similar to a small set of empathetic examples. Crucially, the model does not look at what the utterance is a response to, i.e., the dialogue context. This model performs comparably to other work on standard benchmarks and even outperforms state-of-the-art models for empathetic rationale extraction by 16.7 points on T-F1 and 4.3 on IOU-F1. This indicates that current systems rely on the surface form of the response, rather than whether it is suitable in context. To confirm this, we create examples with dialogue contexts that change the interpretation of the response and show that current systems continue to label utterances as empathetic. We discuss the implications of our findings, including improvements for empathetic benchmarks and how our model can be an informative baseline. ",,,,,,,LIT,FALSE,,,,,,TRUE,
2023,Improving Mental Health Classifier Generalization with Pre-Diagnosis Data,"Yujian Liu*, Laura Biester*, Rada Mihalcea (* = equal contribution)",Proceedings of the International AAAI Conference on Web and Social Media,https://www.laurabiester.com/files/papers/icwsm_prediagnosis2023.pdf,NLP for Healthcare,,,,"@inproceedings{liu2023improving,   title={Improving Mental Health Classifier Generalization with Pre-diagnosis Data},   author={Liu, Yujian and Biester, Laura and Mihalcea, Rada},   booktitle={Proceedings of the International AAAI Conference on Web and Social Media},   volume={17},   pages={566--577},   year={2023} }","Recent work has shown that classifiers for depression detection often fail to generalize to new datasets. Most NLP models for this task are built on datasets that use textual reports of a depression diagnosis (e.g., statements on social media) to identify diagnosed users; this approach allows for collection of large-scale datasets, but leads to poor generalization to out-of-domain data. Notably, models tend to capture features that typify direct discussion of mental health rather than more subtle indications of depression symptoms. In this paper, we explore the hypothesis that building classifiers using exclusively social media posts from before a user’s diagnosis will lead to less reliance on shortcuts and better generalization. We test our classifiers on a dataset that is based on an external survey rather than textual self-reports, and find that using pre-diagnosis data for training yields improved performance with many types of classifiers. ",,,,,,,LIT,FALSE,,,,,,TRUE,
2023,Lexical Measurement of Teaching Qualities,"Laura Biester, Ian Stewart, Laura Hirshfield, Rada Mihalcea, and Sara Pozzi",ASEE 2023,https://www.laurabiester.com/files/papers/asee2023.pdf,"Computational Social Science, Education",,,,"@inproceedings{biesterLEEQ2023,</br>
    author = ""Biester, Laura AND Stewart, Ian AND Hirshfield, Laura AND Mihalcea, Rada AND Pozzi, Sara"",</br>
    title = ""Lexical Measurement of Teaching Qualities"",</br>
    booktitle = ""2023 ASEE Annual Conference \& Exposition"",</br>
    year = ""2023"",</br>
    month = ""June""</br>
}","Students often evaluate their professors’ teaching, both formally (e.g., managed by the institution) and informally (e.g., on websites such as Rate My Professor). However, quantifying the students’ views from their written comments about their professors' abilities can be difficult, because current text processing methods tend to only capture generic concepts such as “positivity,” rather than teaching-specific concepts such as “helpfulness.” To measure students' perception of their professors' teaching, we create lexicons to represent different desired aspects of professors’ performance including quality, helpfulness, clarity, and difficulty. Each lexicon is correlated with one quality and de-correlated with others using a dataset from the popular website Rate My Professor, which contains written evaluations of professors and numerical scores corresponding to different teacher qualities. For example, the correlation method identifies words associated with “helpful” ratings but not “difficulty.”

To ensure that lexicons can extend to a more formal domain of text, we incorporate a dataset including more than 20,000 engineering teaching evaluations, which was provided by the diversity, equity and inclusion center of a large public university in the Midwest United States (henceforth “university dataset”). Using the university dataset, we expand the lexicons by identifying nearest-neighbors to given words according to semantic representations of the words (e.g. “helper” is a neighbor of “helpful” in semantic space; “good” is a neighbor of “wonderful” and “superb”). We validate the final expanded lexicons by correlating the lexicons' use in written reviews with the numerical rating assigned in the review. Professors whose written evaluations contain positive lexicon words (high quality, helpful) also tend to receive higher teaching evaluation scores, while lexicons representing negative teaching qualities (low quality, unhelpful, unclear) are negatively correlated with teaching evaluation scores (p < 0.001).

As a case study for the lexicons, we use them to measure differences in the language used in course evaluations before and during the COVID-19 pandemic. We look at these differences overall, as well as considering differences based on the sex of the instructor. We find changes in the frequency of words representing the quality of instruction, and find that students refer to instructor's helpfulness more often during COVID-19. However, we do not find statistically significant differences in how students discuss male and female instructors, either before or during the pandemic.
",,,,,,,LIT,TRUE,Lexicon for Evaluation of Education Quality (LEEQ),"This resource contains a comprehensive lexicon to measure eight teaching qualities from text. It was created using a combination of automatic methods and manual filtering, and can be used with teaching evaluations or similar texts.",https://github.com/MichiganNLP/LEEQLexicon,18-May-23,Lexicon,TRUE,
2023,We Are in This Together: Quantifying Community Subjective Wellbeing and Resilience,"MeiXing Dong, Ruixuan Sun*, Laura Biester*, Rada Mihalcea (* = equal contribution)",ICWSM 2023,https://arxiv.org/pdf/2208.10766.pdf,Computational Social Science,,,,"@misc{https://doi.org/10.48550/arxiv.2208.10766,</br>
  doi = {10.48550/ARXIV.2208.10766},</br>
  url = {https://arxiv.org/abs/2208.10766},</br>
  author = {Dong, MeiXing and Sun, Ruixuan and Biester, Laura and Mihalcea, Rada},</br>
  keywords = {Social and Information Networks (cs.SI), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},</br>
  title = {We Are in This Together: Quantifying Community Subjective Wellbeing and Resilience},</br>
  publisher = {arXiv},</br>
  year = {2022},</br>
  copyright = {Creative Commons Attribution 4.0 International}</br>
}","The COVID-19 pandemic disrupted everyone's life across the world. In this work, we characterize the subjective wellbeing patterns of 112 cities across the United States during the pandemic prior to vaccine availability, as exhibited in subreddits corresponding to the cities. We quantify subjective wellbeing using positive and negative affect. We then measure the pandemic's impact by comparing a community's observed wellbeing with its expected wellbeing, as forecasted by time series models derived from prior to the pandemic.We show that general community traits reflected in language can be predictive of community resilience. We predict how the pandemic would impact the wellbeing of each community based on linguistic and interaction features from normal times before the pandemic. We find that communities with interaction characteristics corresponding to more closely connected users and higher engagement were less likely to be significantly impacted. Notably, we find that communities that talked more about social ties normally experienced in-person, such as friends, family, and affiliations, were actually more likely to be impacted. Additionally, we use the same features to also predict how quickly each community would recover after the initial onset of the pandemic. We similarly find that communities that talked more about family, affiliations, and identifying as part of a group had a slower recovery.",,,,,,,LIT,FALSE,,,,,,FALSE,
2023,Understanding the Role of Questions in Mental Health Support-Seeking Forums,"Aylin Gunal, Ian Stewart, Rada Mihalcea, Verónica Pérez-Rosas",Health Intelligence Workshop at AAAI 2023,https://web.eecs.umich.edu/~mihalcea/papers/gunal.aaaiw3phiai23.pdf,NLP for Healthcare,,,,"@inproceedings{gunalMHQuestions2023,</br>
   author = {Gunal, Aylin and Stewart, Ian and Mihalcea, Rada and P{\'e}rez-Rosas, Ver{\'o}nica},</br>
   title = {Understanding the Role of Questions in Mental Health Support-Seeking Forums},</br>
    booktitle = {Health Intelligence Workshop at AAAI 2023},</br>
    year = {2023}</br>
}","People who seek mental health help online often receive supportive comments from other users, but their intentions may not be clear, as when someone asks a question that does not require a response. In this work, we explore the role of questions asked in response to support-seeking posts during online interactions centered around mental health support. We introduce a new dataset consisting of 1,089 mental health related post-response pairs from Reddit containing response questions annotated as rhetorical, information-seeking or not applicable. Through several experiments, we find that we can effectively distinguish between rhetorical and information seeking questions using linguistic features. Our findings highlight the importance of surrounding context and functional features (e.g., auxiliary verbs) as opposed to semantic (e.g., words related to mental processes) being significant predictors of question type.",,,,,,,LIT,FALSE,,,,,,FALSE,
2023,Reflection of Demographic Background on Word Usage,"Aparna Garimella, Carmen Banea, Rada Mihalcea","Computational Linguistics Journal, 2023",https://web.eecs.umich.edu/~mihalcea/papers/garimella.cl23.pdf,"Computational Social Science, Semantics",,,,"@article{10.1162/coli_a_00475,</br>
    author = {Garimella, Aparna and Banea, Carmen and Mihalcea, Rada},</br>
    title = ""{Reflection of Demographic Background on Word Usage}"",</br>
    journal = {Computational Linguistics},</br>
    pages = {1-22},</br>
    year = {2023},</br>
    month = {01},</br>
    issn = {0891-2017},</br>
    doi = {10.1162/coli_a_00475},</br>
    url = {https://doi.org/10.1162/coli\_a\_00475},</br>
    eprint = {https://direct.mit.edu/coli/article-pdf/doi/10.1162/coli\_a\_00475/2067077/coli\_a\_00475.pdf},</br>
}","The availability of personal writings in electronic format provides researchers in the fields of linguistics, psychology and computational linguistics with an unprecedented chance to study, on a large scale, the relationship between language use and the demographic background of writers, allowing us to better understand people across different demographics. In this article, we analyze the relation between language and demographics by developing cross-demographic word models to identify words with usage bias, or words that are used in significantly different ways by speakers of different demographics. Focusing on three demographic categories, namely location, gender, and industry, we identify words with significant usage differences in each category and investigate various approaches of encoding a word’s usage, allowing us to identify language aspects that contribute to the differences. Our word models using topic-based features achieve at least 20% improvement in accuracy over the baseline for all demographic categories, even for scenarios with classification into 15 categories, illustrating the usefulness of topic-based features in identifying word usage differences. Further, we note that for location and industry, topics extracted from immediate context are the best predictors of word usages, hinting at the importance of word meaning and its grammatical function for these demographics, while for gender, topics obtain from longer contexts are better predictors for word usage.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,Detection and Recognition of Driver Distraction Using Multimodal Signals,"Kapotaksha Das, Michalis Papakostas, Kais Riani, Andrew Gasiorowski, Mohamed Abouelenien, Mihai Burzo, Rada Mihalcea","ACM Transactions on Interactive Intelligent Systems, Volume 12, Issue 4",https://web.eecs.umich.edu/~mihalcea/papers/das.acmtis22.pdf,Vision and Text,,,,"@article{das2022driverdistraction,</br>
author = {Das, Kapotaksha and Papakostas, Michalis and Riani, Kais and Gasiorowski, Andrew and Abouelenien, Mohamed and Burzo, Mihai and Mihalcea, Rada},</br>
title = {Detection and Recognition of Driver Distraction Using Multimodal Signals},</br>
year = {2022},</br>
issue_date = {December 2022},</br>
publisher = {Association for Computing Machinery},</br>
address = {New York, NY, USA},</br>
volume = {12},</br>
number = {4},</br>
issn = {2160-6455},</br>
url = {https://doi.org/10.1145/3519267},</br>
doi = {10.1145/3519267},</br>
journal = {ACM Trans. Interact. Intell. Syst.},</br>
month = {dec},</br>
articleno = {33},</br>
numpages = {28},</br>
keywords = {thermal (keyword), machine learning, action unit analysis, Distracted driving, multimodal datasets, physiological signal processing, multimodal interaction}</br>
}","Distracted driving is a leading cause of accidents worldwide. The tasks of distraction detection and recognition have been traditionally addressed as computer vision problems. However, distracted behaviors are not always expressed in a visually observable way. In this work, we introduce a novel multimodal dataset of distracted driver behaviors, consisting of data collected using twelve information channels coming from visual, acoustic, near-infrared, thermal, physiological and linguistic modalities. The data were collected from 45 subjects while being exposed to four different distractions (three cognitive and one physical). For the purposes of this paper, we performed experiments with visual, physiological, and thermal information to explore potential of multimodal modeling for distraction recognition. In addition, we analyze the value of different modalities by identifying specific visual, physiological, and thermal groups of features that contribute the most to distraction characterization. Our results highlight the advantage of multimodal representations and reveal valuable insights for the role played by the three modalities on identifying different types of driving distractions.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,Differentially Private Language Models for Secure Data Sharing,"Justus Mattern, Zhijing Jin, Benjamin Weggenmann, Mrinmaya Sachan, Bernhard Schoelkopf",EMNLP 2022,https://zhijing-jin.com/files/papers/DiffPrivLM_EMNLP2022.pdf,Other,,,,"@inproceedings{jin2022private,</br>
   author = {Mattern, Justus and Jin, Zhijing and Weggenmann, Benjamin and Sachan, Mrinmaya and Schoelkopf, Bernhard},</br>
   title = {Differentially Private Language Models for Secure Data Sharing},</br>
    booktitle = {Conference on Empirical Methods in Natural Language Processing},</br>
    year = {2022}</br>
}","To protect the privacy of individuals whose data is being shared, it is of high importance to develop methods allowing researchers and companies to release textual data while providing formal privacy guarantees to its originators. In the field of NLP, substantial efforts have been directed at building mechanisms following the framework of local differential privacy, therefore anonymizing individual text samples before releasing them. In practice, these approaches are often dissatisfying in terms of the quality of their output language due to the strong noise required for local differential privacy. In this paper, we approach the problem at hand using global differential privacy, particularly by training a generative language model in a differentially private manner and consequently sampling data from it. Using natural language prompts and a new prompt-mismatch loss, we are able to create highly accurate and fluent textual datasets taking on specific desired attributes such as sentiment or topic and resembling statistical properties of the training data. We perform thorough experiments indicating that our synthetic datasets do not leak information from our original data, are of high language quality and highly suitable for training models for further analysis on real-world data.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,Logical Fallacy Detection,"Zhijing Jin*, Abhinav Lalwani*, Tejas Vaidhya, Xiaoyu Shen, Yiwen Ding, Zhiheng Lyu, Mrinmaya Sachan, Rada Mihalcea, Bernhard Schoelkopf (* = equal contribution)","Findings of EMNLP, 2022",https://arxiv.org/pdf/2202.13758.pdf,Other,,,,"@inproceedings{jin-etal-2022-logical,</br>
  author    = {Zhijing Jin and Abhinav Lalwani and Tejas Vaidhya and Xiaoyu Shen and Yiwen Ding and Zhiheng Lyu and Mrinmaya Sachan and Rada Mihalcea and Bernhard Sch{\""{o}}lkopf},</br>
  title     = {Logical Fallacy Detection},</br>
    booktitle = ""Findings of the Association for Computational Linguistics: EMNLP 2022"",</br>
    month = dec,</br>
    year = ""2022"",</br>
    publisher = ""Association for Computational Linguistics"",</br>
    url = ""https://arxiv.org/abs/2202.13758"",</br>
}","Reasoning is central to human intelligence. However, fallacious arguments are common, and some exacerbate problems such as spreading misinformation about climate change. In this paper, we propose the task of logical fallacy detection, and provide a new dataset (Logic) of logical fallacies generally found in text, together with an additional challenge set for detecting logical fallacies in climate change claims (LogicClimate). Detecting logical fallacies is a hard problem as the model must understand the underlying logical structure of the argument. We find that existing pretrained large language models perform poorly on this task. In contrast, we show that a simple structure-aware classifier outperforms the best language model by 5.46% on Logic and 4.51% on LogicClimate. We encourage future work to explore this task as (a) it can serve as a new reasoning challenge for language models, and (b) it can have potential applications in tackling the spread of misinformation.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing,"Do June Min, Verónica Pérez-Rosas, Kenneth Resnicow, and Rada Mihalcea",EMNLP 2022,files/min_pair_2022.pdf,"NLP for Healthcare, Conversational Technologies",,files/downloads/PAIR.tgz,,"@inproceedings{min2022pair,</br>
   author = {Min, Do June and P{\'e}rez-Rosas, Ver{\'o}nica and Resnicow, Kenneth and Mihalcea, Rada},</br>
   title = {PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing},</br>
    booktitle = {Conference on Empirical Methods in Natural Language Processing},</br>
    year = {2022}</br>
}","Reflections are a core verbal skill used by mental health counselors to express understanding and acknowledgement of the client’s experience and concerns. In this paper, we propose a system for the automatic evaluation of counselor reflections. Specifically, our system takes as input one dialog turn containing a client prompt likely leading to a reflection and a counselor response to it, and outputs a numeric score indicating the quality of the reflection made by the counselor. We compile a dataset consisting of reflections portraying different levels of reflective listening skills, and propose PromptAware margIn Ranking (PAIR), a novel framework for reflection scoring that contrasts positive and negative prompt and response pairs using adhoc multi-gap and prompt-aware margin ranking losses. Through empirical evaluations and deployment of our system in a real-life educational environment, we show that our scoring model outperforms several baselines on different metrics, and can be used to provide useful feedback to counseling trainees.",,,,,,,LIT,TRUE,PAIR,"A dataset consisting of brief interactions between counselors and clients portraying different levels of reflective listening skills. Each interaction is in English and includes a client prompt, i.e., a client's statement that is usually given to the counseling trainee, paired with counseling responses portraying different levels of reflections skill, i.e., low quality, medium quality, and high quality. We build the dataset using both expert and crowd-sourced annotators and also leverage conversational data from an MI dataset to obtain additional prompt-response pairs from conversations snippets containing reflections.",files/downloads/PAIR.tgz,6-Nov-22,Data,TRUE,
2022,Emotional and Cognitive Changes Surrounding Online Depression Identity Claims,"Laura Biester, James Pennebaker, Rada Mihalcea",PLOS ONE,files/biester_identityclaim_2022.pdf,"Computational Social Science, NLP for Healthcare",,https://zenodo.org/record/7336279,,"@article{biester2022identityclaim,</br>
    doi = {10.1371/journal.pone.0278179},</br>
    author = {Biester, Laura AND Pennebaker, James AND Mihalcea, Rada},</br>
    journal = {PLOS ONE},</br>
    publisher = {Public Library of Science},</br>
    title = {Emotional and cognitive changes surrounding online depression identity claims},</br>
    year = {2022},</br>
    month = {12},</br>
    volume = {17},</br>
    url = {https://doi.org/10.1371/journal.pone.0278179},</br>
    pages = {1-20},</br>
   number = {12}</br>
}","As social media has proliferated, a key aspect to making meaningful connections with people online has been revealing important parts of one’s identity. In this work, we study changes that occur in people’s language use after they share a specific piece of their identity: a depression diagnosis. To do so, we collect data from over five thousand users who have made such a statement, which we refer to as an identity claim. Prior to making a depression identity claim, the Reddit user’s language displays evidence of increasingly higher rates of anxiety, sadness, and cognitive processing language compared to matched controls. After the identity claim, these language markers decrease and more closely match the controls. Similarly, first person singular pronoun usage decreases following the identity claim, which was previously previously found to be indicative of self-focus and associated with depression. By further considering how and to whom people express their identity, we find that the observed longitudinal changes are larger for those who do so in ways that are more correlated with seeking help (sharing in a post instead of a comment; sharing in a mental health support forum). This work suggests that there may be benefits to sharing one’s depression diagnosis, especially in a semi-anonymous forum where others are likely to be empathetic.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot Video Understanding Tasks,"Santiago Castro, Fabian Caba Heilbron",33rd British Machine Vision Conference 2022 (BMVC),https://bmvc2022.mpi-inf.mpg.de/0939.pdf,Vision and Text,,,https://github.com/bryant1410/fitclip,"@inproceedings{Castro_2022_BMVC, </br>
author    = {Santiago Castro and Fabian Caba}, </br>
title     = {FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot Video Understanding Tasks}, </br>
booktitle = {33rd British Machine Vision Conference 2022, {BMVC} 2022, London, UK, November 21-24, 2022}, </br>
publisher = {{BMVA} Press}, </br>
year      = {2022}, </br>
url       = {https://bmvc2022.mpi-inf.mpg.de/0939.pdf} </br>
}","Large-scale pretrained image-text models have shown incredible zero-shot performance in a handful of tasks, including video ones such as action recognition and text-to-video retrieval. However, these models have not been adapted to video, mainly because they do not account for the time dimension but also because video frames are different from the typical images (e.g. containing motion blur, and less sharpness). In this paper, we present a fine-tuning strategy to refine these large-scale pretrained image-text models for zero-shot video understanding tasks. We show that by carefully adapting these models we obtain considerable improvements on two zero-shot Action Recognition tasks and three zero-shot Text-to-Video Retrieval tasks.",BMVC.2022.FitCLIP,FitCLIP: Refining Large-Scale Pretrained Image-Text Models for Zero-Shot Video Understanding Tasks,"Santiago Castro, Fabian Caba Heilbron",BMVC,2022,"London, UK",LIT,FALSE,,,,,,FALSE,
2022,Demographic-Aware Language Model Fine-tuning as a Bias Mitigation Technique,"Aparna Garimella, Akhash Amarnath, Rada Mihalcea",AACL 2022,https://web.eecs.umich.edu/~mihalcea/papers/garimella.aacl22.pdf,"Language Modeling, Computational Social Science",,,,"@inproceedings{garimella22demographic,</br>
   author = {Garimella, A. and Amarnath, A. and Mihalcea, R.},</br>
   title = {Demographic-Aware Language Model Fine-tuning as a Bias Mitigation Technique},</br>
    booktitle = {Proceedings of Asian Association of Computational Linguistics},</br>
    year = {2022}</br>
}","BERT-like language models (LMs), when exposed to large unstructured datasets, are known to learn and sometimes even amplify the biases present in such data. These biases generally reflect social stereotypes with respect to gender, race, age, and others. In this paper, we analyze the variations in gender and racial biases in BERT, a large pre-trained LM, when exposed to different demographic groups. Specifically, we investigate the effect of fine-tuning BERT on text authored by historically disadvantaged demographic groups in comparison to that by advantaged groups. We show that simply by fine-tuning BERT-like LMs on text authored by certain demographic groups can result in the mitigation of social biases in these LMs against various target groups.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,Text-Aware Graph Embeddings for Donation Behavior Prediction,"MeiXing Dong, Xueming Xu, Rada Mihalcea",TextGraphs Workshop at COLING 2022,files/dong_textgraphs_2022.pdf,"Graph-based NLP, Computational Social Science",,,,"@inproceedings{dog-etal-2022-graph-embeddings,</br>
    title = ""Text-Aware Graph Embeddings for Donation Behavior Prediction"",</br>
    author = ""Dong, MeiXing and Xu, Xueming and Mihalcea, Rada"",</br>
    booktitle = ""TextGraphs Workshop at COLING 2022"",</br>
    month = oct,</br>
    year = ""2022"",</br>
    address = ""Gyeongju, Republic of Korea"",</br>
    publisher = ""International Committee on Computational Linguistics""
}","Predicting user behavior is essential for a large number of applications including recommender and dialog systems, and more broadly in domains such as healthcare, education, and economics. In this paper, we show that we can effectively predict donation behavior by using text-aware graph models, building upon graphs that connect user behaviors and their interests. Using a university donation dataset, we show that the graph representation significantly improves over learning from textual representations. Moreover, we show how incorporating implicit information inferred from text associated with the graph entities brings additional improvements. Our results demonstrate the role played by text-aware graph representations in predicting donation behavior.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,Towards Understanding the Relation between Gestures and Language,"Artem Abzaliev, Andrew Owens, Rada Mihalcea",COLING 2022,files/abzaliev_coling_2022.pdf,Vision and Text,,https://drive.google.com/drive/folders/10Y2JGFhXtV3cd1loC3kR_v4zlJMQ5Zng?usp=sharing,https://github.com/MichiganNLP/gestures-language,"@inproceedings{abzaliev-etal-2022-gestures,</br>
    title = ""Towards Understanding the Relation between Gestures and Language"",</br>
    author = ""Abzaliev, Artem and Owens, Andrew and Mihalcea, Rada"",</br>
    booktitle = ""COLING"",</br>
    month = oct,</br>
    year = ""2022"",</br>
    address = ""Gyeongju, Republic of Korea"",</br>
    publisher = ""International Committee on Computational Linguistics""
}","In this paper, we explore the relation between gestures and language. Using a multimodal dataset, consisting of TED talks where the language is aligned with the gestures made by the speakers, we adapt a semi-supervised multimodal model to learn gesture embeddings. We show that gestures are predictive of the native language of the speaker, and that gesture embeddings further improve language prediction result. In addition, gesture embeddings might contain some linguistic information, as we show by probing embeddings for psycholinguistic categories. Finally, we analyze the words that lead to the most expressive gestures and find that function words drive the expressiveness of gestures. Our code is available at https://github.com/MichiganNLP/gestures-language.",,,,,,,LIT,FALSE,,,,,,FALSE,
2022,WildQA: In-the-Wild Video Question Answering,"Santiago Castro, Naihao Deng, Pingxuan Huang, Mihai Burzo, Rada Mihalcea",COLING 2022,https://arxiv.org/pdf/2209.06650.pdf,Vision and Text,,https://lit.eecs.umich.edu/wildqa/,https://lit.eecs.umich.edu/wildqa/,"@inproceedings{castro-etal-2022-in-the-wild,</br>
    title = ""In-the-Wild Video Question Answering"",</br>
    author = ""Castro, Santiago  and Deng, Naihao  and Huang, Pingxuan  and Burzo, Mihai G.  and Mihalcea, Rada"",</br>
    booktitle = ""COLING"",</br>
    month = oct,</br>
    year = ""2022"",</br>
    address = ""Gyeongju, Republic of Korea"",</br>
    publisher = ""International Committee on Computational Linguistics"",</br>
    url = ""https://aclanthology.org/2022.coling-1.496"",</br>
    pages = ""5613--5635""</br>
}","Existing video understanding datasets mostly focus on human interactions, with little attention being paid to the ""in the wild"" settings, where the videos are recorded outdoors. We propose WILDQA, a video understanding dataset of videos recorded in outside settings. In addition to video question answering (Video QA), we also introduce the new task of identifying visual support for a given question and answer (Video Evidence Selection). Through evaluations using a wide range of baseline models, we show that WILDQA poses new challenges to the vision and language research communities. The dataset is available at https://lit.eecs.umich.edu/wildqa/.",,,,,,,LIT,TRUE,WildQA: In-the-Wild Video Question Answering,WildQA is a video understanding dataset of videos recorded in outside settings. This project also introduce the Video Evidence Selection task.,https://lit.eecs.umich.edu/wildqa/,23-Oct-22,Data + Code,TRUE,
2022,How Well Do You Know Your Audience? Toward Socially-aware Question Generation,"Ian Stewart, Rada Mihalcea",SIGDIAL 2022,https://arxiv.org/pdf/2110.08445.pdf,Conversational Technologies,,,,"@inproceedings{Stewart2022Audience,</br>
    title = ""How Well Do You Know Your Audience? Toward Socially-aware Question Generation"",</br>
    author = ""Stewart, Ian and Mihalcea, Rada"",</br>
    booktitle = ""Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue"",</br>
    month = sep,</br>
    year = ""2022""</br>
}","When writing, a person may need to anticipate questions from their audience, but different social groups may ask very different types of questions. If someone is writing about a problem they want to resolve, what kind of follow-up question will a domain expert ask, and could the writer better address the expert's information needs by rewriting their original post? In this paper, we explore the task of socially-aware question generation. We collect a data set of questions and posts from social media, including background information about the question-askers' social groups. We find that different social groups, such as experts and novices, consistently ask different types of questions. We train several text-generation models that incorporate social information, and we find that a discrete social-representation model outperforms the text-only model when different social groups ask highly different questions from one another. Our work provides a framework for developing text generation models that can help writers anticipate the information expectations of highly different social groups.",,,,,,,LIT,FALSE,,,,,,FALSE,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,
